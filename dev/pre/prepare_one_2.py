#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, write to the Free Software
#  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
#  MA 02110-1301, USA.
#  

import sys
from stop_words import get_stop_words
from nltk.tokenize import word_tokenize
import argparse
import numpy 
import math
import string
import random

def escape( str ):  # Escape some XML; lifted from http://stackoverflow.com/questions/1546717/python-escaping-strings-for-use-in-xml
    str = str.replace("<", "&lt;")
    str = str.replace(">", "&gt;")
    str = str.replace("&", "&amp;")
    # str = str.replace("\"", "&quot;")
    return str


reload(sys)
sys.setdefaultencoding("utf-8")

parser = argparse.ArgumentParser()
parser.add_argument("--percentage", dest="percentage", type=float, default=10.0, help="Percentage (default 10%)")
parser.add_argument('-v', '--verbose', help='Verbose Mode', dest="verbose", action='store_true',default=False)
parser.add_argument('--include_stopwords', help="Don't exclude stopwords", dest="include_stopwords", action="store_true", default=False)
parser.add_argument('--include_punctuation', help="Don't exclude punctuation", dest="include_punct", action="store_true", default=False)
parser.add_argument('--no_hint', help="Provide no hint", dest="no_hint", action="store_true", default=False)
parser.add_argument("reftextfile",help="Reference text")
parser.add_argument("hinttextfile",help="Hint text")
parser.add_argument("resultfile",help="Result file")
parser.add_argument('--setid', help='Evaluation set identifier', dest='setid', default="defaultsetid")
parser.add_argument('--docid', help='Document identifier', dest='docid', default="defaultdocid")
parser.add_argument('--sl',help="Source language", dest="sl", default="unk")
parser.add_argument('--tl',help="Target language", dest="tl", default="unk")
parser.add_argument("--system", help="MT system", dest="system", default="unk")
parser.add_argument('--adjacent_gaps_not_ok', help="Adjacent gaps are not allowed.", dest="adjacent_gaps_not_ok", action="store_true", default=False)

args = parser.parse_args()

# Read reference text file and hint text file
reftext=open(args.reftextfile).readlines()

selected=0 # remnant of old code, selecting just one sentence
summary=reftext[0]
print summary, "[", selected, "]"
   
hinttext=open(args.hinttextfile).readlines()
if args.no_hint :
	hinttext=["[No hint, you are on your own!]"]
        system="NONE"
else :
        system=args.system

   
if args.include_stopwords : # meaning gaps can be plugged at stopwords
   stop_words=[]
else :
   try :
      stop_words = get_stop_words('args.tl')
      if args.tl=="en" : # needed as a result of NLTK tokenization
		  for sw in [u"n't", u"'s", u"'re"] :
			  stop_words.append(sw)
   except :
      print "Could not get stopwords for language ", args.tl 
      print "Will not consider stopwords"
      stop_words=[]
      
# This punctuation list needs to be improved
punct = [string.punctuation[i] for i in range(len(string.punctuation))]
punct.append("''") # these are generated by word_tokenize. 
punct.append("``")

#punct = [u",", u"?", u".", u":", u";", u"(", u")", u"[", u"]", u"{", u"}", u"%", u"$", u"#", u"!", u"-"]
if not args.include_punct :
   for sw in punct :
       stop_words.append(sw)
       

ss = 	word_tokenize(summary)
# ss =  ['<s>'] + ss + ['</s>']
lss = len(ss) 
basesentence=" ".join(ss)
#  for i, (prob, length, oov) in enumerate(model.full_scores(basesentence)):
#      print("i={0} prob={1} length={2}, oov={3} stretch='{4}'".format(i, prob, length, oov, ' '.join(ss[i+2-length:i+2])))
bestdiff=-float("inf")
values = lss * [-float("inf")]
bestk=-1
log102=math.log10(2.0)

onegramcount=65536 # fake number for code remnants to work

for i in range(0,lss) :
   if (ss[i]).lower() not in stop_words :
      entropy=random.random()*math.log(onegramcount,2.0) # Not really an entropy -- code remnant

if args.verbose :          
   print "Selected position:", i, "(", ss[bestk], ")" # code remnant --- ugly

# Rank words according to "entropy" --- there is no entropy, my friend, it is a random number
# All of this could be massively simplified, no time now..
nholes = max(1,int(0.5 + lss * args.percentage / 100.0))
if nholes == 0 :
   nholes = 1       # Only for sentences 5 words or shorter 
# print lss, nholes
val = numpy.array(values)
ival = val.argsort()
if args.verbose :
     for i in range(lss-1,-1,-1) : 
        print "{0} {1} {2:7.2f} {3}".format(i,ival[i],values[ival[i]],ss[ival[i]])
anss = ss 
holecount=0
holelist=[]
for i in range(lss-1,-1,-1) :
     if ss[ival[i]].lower() not in stop_words :  # when stopwords list is empty, all holes are OK
#        print ival[i], ss[ival[i]]
        if holecount<nholes :
           will_plug=True # default is plugging
           if args.adjacent_gaps_not_ok :              
              for previoushole in holelist:   # I'm sure I can factor this out in some way.
                  print "current rank", i, "position" , ival[i], "comparing with", previoushole
                  if math.fabs(previoushole-ival[i])==1 : # holes together
                     print "Holes together"
                     will_plug = will_plug and False #  
                  else : # this only needs to be done if stopwords are not taken into account
                     if not(args.include_stopwords) :
                        plug_condition = False # unless a non-stopword is found between the two
                        if previoushole < ival[i]:
                           for pos in range(previoushole+1,ival[i]) :
                              if ss[pos] not in stop_words :
                                 plug_condition = True
                        else:  
                           for pos in range(ival[1]+1,previoushole) :
                              if ss[pos] not in stop_words :
                                 plug_condition = True
                        will_plug = will_plug and plug_condition
           print "will plug", will_plug
           if will_plug :
              if args.verbose:
                 print "{0} in position {3} has rank {1} and entropy {2:.2f}".format(ss[ival[i]], i, values[ival[i]], ival[i])
              anss[ival[i]]=ss[ival[i]] 
              holelist.append(ival[i])
              holecount = holecount + 1
	

res=open(args.resultfile,"w")

res.write('<set id="{0}" source-language="{1}" target-language="{2}">\n'.format(args.setid, args.sl, args.tl))

docmode="-doc" # all is -doc in the kazakh project

entmode="-ent" # all is -ent (i.e. random) in the kazakh project


res.write('<seg id="{0}{1}" doc-id="{2}" hide-source="True" type="{3}:{4}:{5}:{6}">\n'.format("editme::",args.docid, args.docid, args.percentage, system, docmode, entmode))

res.write('<source>Dummy text, not shown</source>\n') # empty source - we're not using it, but need to provide it
# for Appraise

res.write("<reference>") # wrong name, but used like this

# Lots of code down here dealt with multi-line hint texts and references
# They are not needed for the Kazakh project
print "Hint text: "
temp=""
for j,line in enumerate(hinttext) :
	if j==selected and docmode=="+doc" : # not sure why I need the
                                            # second condition
                                            # but a bug was found
	   print ">>>" + line.strip("\n")
	   temp = temp + "[b]" + line.strip("\n") + "[/b]" + "@@@"
	else :
	   print line.strip("\n")
	   temp = temp + line.strip("\n") + "@@@"
print "________________________________________________"
temp=temp.rstrip("@@@")
temp=escape(temp) # for ampersands and such
res.write(temp)
res.write("</reference>\n")     
	
print "________________________________________________"
print "Problem:"
problem=""
solution=""
# print holelist
for pos, word in enumerate(anss) :
#   print pos, word
   if pos in holelist :
#	   print pos, word, "in holelist"
	   problem = problem + " { }" 
	   solution = solution + ";" + anss[pos]
   else :
	   problem = problem + " " + anss[pos]
solution=solution.lstrip(";")
solution=escape(solution)



# print " ".join(anss)
print problem

print "________________________________________________"
print "Solution:"
print solution
print "________________________________________________"

res.write('<translation system="{0}" type="{1}" fill="{2}" keys="{3}">\n'.format(system, "simple", ";" * (len(holelist)-1), solution))
res.write(escape(problem))
res.write('</translation>\n')
res.write('</seg>\n')
res.write('</set>\n')

# Later we will print a complete job with more than one problem
